{"name":"Machine-learning","tagline":"","body":"### Welcome to Coursera Prediction Assignment Page.\r\nby: Ehsan Moazen Zadeh\r\n\r\n1_I uploaded packages\r\n>library(caret)\r\n\r\n2_I set an overall seed to make reproducible results\r\n>set.seed(1221)\r\n\r\n3_I read data to R for training and testing\r\n>training<-read.csv(\"pml-training.csv\")\r\n\r\n>testing<-read.csv(\"pml-testing.csv\")\r\n\r\n3_Exploratory data analysis:\r\n\r\n_First, I wanted to have an overall view of the data\r\n>dim(training)\r\n\r\n>colnames(training)\r\n\r\n>summary(training)\r\n\r\n_ “summary” code did not help that much as there were 160 variables\r\n\r\n_I skipped plotting the data for the same reason of many variables\r\n\r\n_I wanted to have an overview of the missing data\r\n>complete.cases(training)\r\n\r\n_much missing data!\r\nSo, I considered using “knnImpute” for pre-Processing in later steps\r\n\r\n_I wanted to have an overview of the correlations between variables\r\n>M<-abs(cor(training[,-160]))\r\n\r\n_above code did not work because it only works on numeric variables\r\nSo, as I couldn’t have an estimate of the correlations, I considered “pca”\r\nas a probable candidate for pre-Processing\r\n\r\n_next, I checked for the variables with near zero variance\r\n>nsv<-nearZeroVar(training,saveMetrics=TRUE)\r\n\r\n>nsv\r\n\r\n_60 near zero variables!!!\r\n\r\n\r\n4_Covariate creation:\r\n\r\n_I tried many ways of coding to exclude the near zero variables from the training set, including “for” loop, “apply”, “rep”. but none of them worked perfectly as I am naïve in coding. Finally I came up with this code:\r\n\r\n>for (i in 1:160){\r\n\r\n    x<-nsv[i,4]\r\n\r\n    if (x==\"TRUE\"){\r\n\r\n        training<-training[,-i]\r\n\r\n        nsv<-nsv[-i,]\r\n\r\n    }\r\n\r\n }\r\n\r\n_each time that I ran the code above, it reduced the number of variables with near zero variance but produced an error in the midway and did not exclude them completely; however, it would omit all the 60 near zero variables after 4 times of repeating the code! So, I wrote the code 4 times consecutively for now.( I may find a better way to omit the 60 near zeroes in future.) At the end, I checked for the results:\r\n>dim(training)\r\n\r\n>dim(nsv)\r\n\r\n_my options for pre-Processing were “knnImpute”, ”pca”, “center”, “scale” up to this step. I think all of them were needed if I would choose a regression model rather than a non-parametric tree\r\n\r\n5_Final model:\r\n\r\n_according to the high number of variables, missing values and the fact that there were 19622 observations, I found the randomForest a proper choice. It would be more accurate than other models for such a data set.\r\n>library(randomForest)\r\n\r\n_as I chose to use randomForest(“rf”), there were no need to apply cross validation methods like “cv” or “boot” through *trainControl* argument. Here is a link for more information on this matter:\r\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\r\n\r\n_also, there was no real need for that much pre-Processing in comparison to regression models. So, I just chose “knnImpute” to cover missing data. I used *train* function once with the “knnImpute” and the other time without “knnImpute”. Because there was not a significant difference in the accuracy of the randomForest model on training data set, I preferred not to use “knnImpute” in order to decrease the amount of computations and time consumption.\r\n\r\n>modFit<-train(training$classe~.,data=training,method=\"rf\",prox=TRUE)\r\n\r\n>modFit\r\n\r\n>modFit$finalModel\r\n\r\n_Accuracy was 98.92%. Out-of-Bag (oob) error estimate was 0.74%.\r\n I predicted that there might be an error rate higher than oob when applying the model to the testing set. Also, the really high accuracy of the model would bring the concern of over-fitting. Anyhow, I had no more time to try other models and I decided to submit this one.\r\n\r\n_here is the final code for trying the model on the testing data set:\r\n\r\n\r\n>  confusionMatrix(testing$classe,predict(modFit,testing))\r\n\r\n \r\n\r\nThank you for reading\r\n\r\n(The codes are provided below in sequence)\r\n\r\n\r\n```\r\nlibrary(caret)\r\nset.seed(1221)\r\ntraining<-read.csv(\"pml-training.csv\")\r\ntesting<-read.csv(\"pml-testing.csv\")\r\ndim(training)\r\ncolnames(training)\r\nsummary(training)\r\ncomplete.cases(training)\r\nM<-abs(cor(training[,-160]))\r\nnsv<-nearZeroVar(training,saveMetrics=TRUE)\r\nnsv\r\nfor (i in 1:160){\r\nx<-nsv[i,4]\r\nif (x==\"TRUE\"){\r\ntraining<-training[,-i]\r\nnsv<-nsv[-i,]\r\n}\r\n}\r\nfor (i in 1:160){\r\nx<-nsv[i,4]\r\nif (x==\"TRUE\"){\r\ntraining<-training[,-i]\r\nnsv<-nsv[-i,]\r\n}\r\n}\r\nfor (i in 1:160){\r\nx<-nsv[i,4]\r\nif (x==\"TRUE\"){\r\ntraining<-training[,-i]\r\nnsv<-nsv[-i,]\r\n}\r\n}\r\n\r\nfor (i in 1:160){\r\nx<-nsv[i,4]\r\nif (x==\"TRUE\"){\r\ntraining<-training[,-i]\r\nnsv<-nsv[-i,]\r\n}\r\n}\r\ndim(training)\r\ndim(nsv)\r\nlibrary(randomForest)\r\nmodFit<-train(training$classe~.,data=training,method=\"rf\",prox=TRUE)\r\nmodFit\r\nmodFit$finalModel\r\nconfusionMatrix(testing$classe,predict(modFit,testing))\r\n\r\n```\r\n\r\n\r\n### Authors and Contributors\r\nemplus@Ymail.com\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}